{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDx2foFQV_rl"
   },
   "outputs": [],
   "source": [
    "%pip install pretty_midi\n",
    "%pip install tensorflow\n",
    "%pip install music21\n",
    "%pip uninstall fluidsynth -y\n",
    "%pip install --upgrade fluidsynth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 8559,
     "status": "ok",
     "timestamp": 1729777067292,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "TSjP-8ufWRa3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import pathlib\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import music21\n",
    "import tensorflow as tf\n",
    "import fluidsynth\n",
    "import my_functions\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global things used throughout the notebook\n",
    "importlib.reload(my_functions)\n",
    "\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 16000\n",
    "\n",
    "# length of trainig sequences\n",
    "seq_length = 20\n",
    "\n",
    "# Size of pitch vocab\n",
    "vocab_size = 128\n",
    "\n",
    "# Keys that will get extracted into the training set. This are the inputs to the model!\n",
    "key_order = ['pitch', 'contour', 'step', 'duration', 'tempo']\n",
    "\n",
    "# Normalizer for keys   This is used to normalize the inputs\n",
    "#  MUST HAVE SAME DIMENSION AS KEY_ORDER!!\n",
    "key_normalizer = [vocab_size, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and massage it for training\n",
    "\n",
    "# This loads up all the notes in the dataset\n",
    "pitchInst = my_functions.extract_notes()\n",
    "\n",
    "# Calc the gap between start of consecutive notes\n",
    "pitchInst['step'] = pitchInst['start'] - pitchInst['start'].shift(1)\n",
    "\n",
    "# Fix up the first one cause of the wacky shift problem\n",
    "pitchInst.loc[0,\"step\"] = 0\n",
    "\n",
    "# Calculate the inverval between successive notes\n",
    "pitchInst['interval'] = (pitchInst['pitch'] - pitchInst['pitch'].shift(1))\n",
    "\n",
    "# Fix up the first one cause of the wacky shift problem\n",
    "pitchInst.loc[0, 'interval'] = 0\n",
    "\n",
    "# apply a contour function\n",
    "pitchInst['contour'] = pitchInst['interval'].apply(my_functions.contour)\n",
    "\n",
    "n_notes = len(pitchInst)\n",
    "pitchInst.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of partial training sequences (no end of one song right into the next)\n",
    "\n",
    "# Create an empty data set with same shape\n",
    "train_sub = pd.DataFrame(None, columns=pitchInst.columns)\n",
    "\n",
    "# Loop through all melid values to trim partial seqeunces off\n",
    "# to do subset just change the start range of the loop to 200 as you had before\n",
    "# for i in range(pitchInst['melid'].min(), pitchInst['melid'].max(), 1):\n",
    "for i in range(50, pitchInst['melid'].max(), 1):\n",
    "    song = pitchInst[pitchInst['melid'] == i]\n",
    "    # This is not super efficient, but it works.  \n",
    "    train_sub = pd.concat([train_sub, song.head(len(song) - len(song) % seq_length)], ignore_index=True)  # append only sets of seq_length\n",
    "\n",
    "train_notes = np.stack([train_sub[key] for key in key_order], axis=1)\n",
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1729777314906,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "BTRgKfp-oBcf"
   },
   "outputs": [],
   "source": [
    "# from tensorFlow MusGen tutorial \n",
    "def create_sequences(\n",
    "    dataset: tf.data.Dataset,\n",
    "    seq_length: int,\n",
    "    vocab_size: int,\n",
    ") -> tf.data.Dataset:\n",
    "  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
    "  seq_length = seq_length+1\n",
    "\n",
    "  # Take 1 extra for the labels\n",
    "  windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "\n",
    "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "  sequences = windows.flat_map(flatten)\n",
    "\n",
    "  # Normalize note pitch (is this a good idea?)\n",
    "  def scale_pitch(x):\n",
    "    x = x/key_normalizer\n",
    "    return x\n",
    "\n",
    "  # Split the labels\n",
    "  def split_labels(sequences):\n",
    "    inputs = sequences[:-1]\n",
    "    labels_dense = sequences[-1]\n",
    "    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "    return scale_pitch(inputs), labels\n",
    "    #return inputs, labels\n",
    "\n",
    "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1729777317788,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "vvUPy1h-pgwL",
    "outputId": "772d3214-91f8-4e23-f674-9c0c29546add"
   },
   "outputs": [],
   "source": [
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
    "seq_ds.__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1729777346217,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "FAdNRRuhxD2b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = n_notes - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1729777351153,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "0MoxpDNIxJF1",
    "outputId": "4b5b7093-7e45-4672-b4b9-b351ca9ae3cb"
   },
   "outputs": [],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1729777377807,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "U6nNWGwJyDQE"
   },
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "  mse = (y_true - y_pred) ** 2\n",
    "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "  return tf.reduce_mean(mse + positive_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1729777385441,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "yaHEn45JyExj",
    "outputId": "9486ced4-b5cb-4403-a0d6-73293f0d06de"
   },
   "outputs": [],
   "source": [
    "# definition for the inpus.  Note how num of inputs is realted to size of key_order global\n",
    "input_shape = (seq_length, len(key_order))\n",
    "learning_rate = 0.010\n",
    "\n",
    "#change input layers here? to suit contour\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "#hidden layers\n",
    "x = tf.keras.layers.LSTM(128, return_sequences=True, activation='tanh')(inputs)\n",
    "x = tf.keras.layers.LSTM(16, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(16, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(16, return_sequences=False)(x)\n",
    "\n",
    "\n",
    "\n",
    "# 128 outputs for pitch for OHE\n",
    "outputs = {\n",
    "  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n",
    "  'step': tf.keras.layers.Dense(1, name='step')(x),\n",
    "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = {\n",
    "      'pitch':tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "          from_logits=True),\n",
    "      'step': mse_with_positive_pressure,\n",
    "      'duration': mse_with_positive_pressure,\n",
    "}\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1729777404726,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "nxD0f65oyGQ8"
   },
   "outputs": [],
   "source": [
    "# these are the three outputs of the model\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    loss_weights={\n",
    "        'pitch': 0.80,\n",
    "        'step': 1.0,\n",
    "        'duration':1.0,\n",
    "    },\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "error",
     "timestamp": 1729777408966,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "0uYYRkKdyhTW",
    "outputId": "6612f8d7-48c3-49a1-8487-e2c0fa695763"
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1729702148836,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "zAww8xc7zAqc"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./training_checkpoints/ckpt_{epoch}.weights.h5',\n",
    "        save_weights_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4492,
     "status": "ok",
     "timestamp": 1729702158732,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "fxjUzIZUBFBW",
    "outputId": "ca635b70-07f4-4bec-e6ee-afc9a1e81462"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIMee7mLBQ5z"
   },
   "outputs": [],
   "source": [
    "def predict_next_note(\n",
    "    notes: np.ndarray,\n",
    "    model: tf.keras.Model,\n",
    "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
    "  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  pitch_logits = predictions['pitch']\n",
    "  step = predictions['step']\n",
    "  duration = predictions['duration']\n",
    "\n",
    "  pitch_logits /= temperature \n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1) \n",
    "  pitch = tf.squeeze(pitch, axis=-1) \n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "\n",
    "  # `step` and `duration` values should be non-negative\n",
    "\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "  \n",
    "\n",
    "  return int(pitch), float(step), float(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=pathlib.Path('Jazzomat_midi_folder')\n",
    "filenames = glob.glob(str(data_dir/\"*.mid\"))\n",
    "sorted_filenames = sorted(filenames)\n",
    "sample_file = filenames[8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1.0\n",
    "num_predictions = 60\n",
    "\n",
    "# pick one of the midi files\n",
    "# test_file = sorted_filenames[24]\n",
    "\n",
    "# test_notes = my_functions.midi_to_notes(test_file)\n",
    "# # Calculate the inverval between successive notes\n",
    "# test_notes['interval'] = (test_notes['pitch'] - test_notes['pitch'].shift(1))\n",
    "# # Fix up the first one cause of the wacky shift problem\n",
    "# test_notes.loc[0, 'interval'] = 0\n",
    "# # apply a contour function\n",
    "# test_notes['contour'] = test_notes['interval'].apply(my_functions.contour)\n",
    "#easier to sort testing dataframes\n",
    "#dfs = dict(tuple(pitchInst.groupby('melid')))\n",
    "song = 25\n",
    "test_notes = pitchInst[pitchInst['melid'] == song].reset_index()\n",
    "test_notes.loc[0, 'step'] = 0.0\n",
    "sample_notes = np.stack([test_notes[key] for key in key_order], axis=1)\n",
    "# input_notes = tf.data.Dataset.from_tensor_slices(sample_notes[:seq_length])\n",
    "\n",
    "\n",
    "# The initial sequence of notes; pitch is normalized similar to training sequences\n",
    "input_notes = (sample_notes[:seq_length] / np.array(key_normalizer))\n",
    "\n",
    "# This is the tempo of the midi input file...\n",
    "tempo = test_notes['tempo'].iloc[seq_length]\n",
    "\n",
    "\n",
    "generated_notes = []\n",
    "prev_start = 0\n",
    "input_note = input_notes[-1]\n",
    "#contour = 0  #initial contour should be last contour of input sequence\n",
    "for i in range(num_predictions): #THERE ARE PROBLEMS HERE\n",
    "  pitch, step, duration = predict_next_note(input_notes, model, temperature)\n",
    "  start = prev_start + step\n",
    "  end = start + duration\n",
    "  # TODO:  Should this be input_note[0] or the last note?\n",
    "  interval = pitch - input_note[0]\n",
    "  contour = my_functions.contour(interval)\n",
    "  # TODO:\n",
    "  # This line has to change when you change the inputs to the model.  The input_note\n",
    "  # that is getting appended to input notes needs to have the correct number of \n",
    "  # fields cause it is gonna get fed back into the model.predict function\n",
    "  input_note = (pitch, contour, step, duration, tempo)\n",
    "  generated_notes.append((*input_note, start, end))\n",
    "  input_notes = np.delete(input_notes, 0, axis=0)\n",
    "  input_notes = np.append(input_notes , np.expand_dims(input_note, 0), axis=0) \n",
    "  prev_start = start\n",
    "  \n",
    "\n",
    "generated_notes = pd.DataFrame(\n",
    "    generated_notes, columns=(*key_order, 'start', 'end'))\n",
    "\n",
    "generated_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_notes = test_notes[:seq_length]\n",
    "start_df = test_notes.drop(['interval'], axis=1)\n",
    "start_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string together the first training data and the generated notes\n",
    "full_sequence = pd.concat([start_df, generated_notes], ignore_index=True)\n",
    "full_sequence[['pitch', 'step', 'duration']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_to_midi(\n",
    "  notes: pd.DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = pretty_midi.PrettyMIDI(sample_file)\n",
    "example_file = 'contourExampleTempo.midi'\n",
    "instrument = pm.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)\n",
    "example_pm = my_functions.notes_to_midi(full_sequence[['pitch', 'step', 'duration']], out_file=example_file, instrument_name=instrument_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_piano_roll(full_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_distributions(generated_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_distributions(test_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbAUZAKMT3LWx3S3x1qvHL",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
