{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDx2foFQV_rl"
   },
   "outputs": [],
   "source": [
    "%pip install pretty_midi\n",
    "%pip install tensorflow\n",
    "%pip install music21\n",
    "%pip uninstall fluidsynth -y\n",
    "%pip install --upgrade fluidsynth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "executionInfo": {
     "elapsed": 8559,
     "status": "ok",
     "timestamp": 1729777067292,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "TSjP-8ufWRa3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import pathlib\n",
    "import collections\n",
    "import datetime\n",
    "import glob\n",
    "import music21\n",
    "import tensorflow as tf\n",
    "import fluidsynth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Gen using LSTM model\n",
    "\n",
    "This project will use a 4 layer keras LSTM model to predict notes based on training from a famous jazz recording captures that were converted to midi.\n",
    "\n",
    "The notebook has 3 main sections.\n",
    "* Training Data Preparation\n",
    "* Model Definition and fit\n",
    "* Predictions based on sample input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Some conversion and database i/o functions were split into a separate python file to help readability of this notebook.  This are loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell defines global constants that are used throughout the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global things used throughout the notebook\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# length of trainig sequences\n",
    "seq_length = 20\n",
    "\n",
    "# Size of pitch vocab\n",
    "vocab_size = 25\n",
    "\n",
    "# Keys that will get extracted into the training set. This are the inputs to the model!\n",
    "key_order = ['interval', 'step', 'duration', 'tempo', 'instrument_num', 'key_num']\n",
    "\n",
    "# Songs to leave out of training\n",
    "skip_list = [3, 130, 222]\n",
    "\n",
    "# should you trip of remainders on each song by modulo seq_length\n",
    "trim_song_ends = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell will load training data using a SQL query and calculate some differential values\n",
    "* see my_functions.extract_notes() for the sql query to the wjazzd.db\n",
    "* interval is the diffenrence in pitch between successive notes\n",
    "* countour generates an abstraction based on interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads up all the notes in the dataset\n",
    "pitchInst = my_functions.extract_notes()\n",
    "\n",
    "# # Calc the gap between start of consecutive notes\n",
    "pitchInst['step'] = pitchInst['start'] - pitchInst['start'].shift(1)\n",
    "#fix problems at boundaries\n",
    "pitchInst['step'].fillna((pitchInst['step'].median()), inplace=True)\n",
    "\n",
    "# Calculate the inverval between successive notes\n",
    "pitchInst['interval'] = pitchInst['pitch'] - pitchInst['pitch'].shift(1)\n",
    "#fix problems at boundaries\n",
    "pitchInst['interval'].fillna(0, inplace=True)\n",
    "\n",
    "# apply a contour function\n",
    "pitchInst['contour'] = pitchInst['interval'].apply(my_functions.contour)\n",
    "\n",
    "pitchInst.head()\n",
    "pitchInst['instrument'].dtype\n",
    "#pitchInst['instrument_num'] = pitchInst['instrument'].cat.codes\n",
    "\n",
    "# fix out of bound steps.  Negative steps will have the median step size\n",
    "median = pitchInst['step'].median()\n",
    "pitchInst.loc[pitchInst['step'] < 0.0, 'step'] = median\n",
    "#binds interval to range to ensure vocab size, two octaves either direction\n",
    "pitchInst['interval'] = np.clip(pitchInst['interval'], -24.0, +24.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn to alpha numeric lables into numbers for training input\n",
    "* instrument_num maps to the type of instrument used in the solo\n",
    "* key_num maps to the musical key that the tune was in (Bb-maj for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "pitchInst['instrument_num'] = le.fit_transform(pitchInst['instrument']).astype(float)\n",
    "pitchInst['key_num'] = le.fit_transform(pitchInst['key']).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trim off extraneous notes from the sequences\n",
    "Make sure the training set is an integer multiple of seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if trim_song_ends:\n",
    "    #REMOVE REMAINDERS FROM TRAINING SET HERE\n",
    "    dfs = dict(tuple(pitchInst.groupby('melid')))\n",
    "\n",
    "    # Empty array to build up\n",
    "    train_subset = pd.DataFrame(None, columns=pitchInst.columns)\n",
    "    # Loop through the solos\n",
    "    for i, df in dfs.items():\n",
    "        # skip the first 10 songs so they can be used for test genearation\n",
    "        if (i not in skip_list):\n",
    "            n = len(dfs[i])%seq_length  # leftovers\n",
    "            dfs[i].drop(df.tail(n).index, inplace = True) # Drop the remnants\n",
    "            train_subset = pd.concat([train_subset, dfs[i]], ignore_index=True)  # append to the set\n",
    "\n",
    "    # Note: There is probably a way to just flatten dfs after the loop with the drops instead\n",
    "    # of the repeated calls to pd.concat()\n",
    "\n",
    "\n",
    "    # n_notes will be used later to build batches\n",
    "    n_notes = len(train_subset)\n",
    "    train_notes = np.stack([train_subset[key] for key in key_order], axis=1)\n",
    "else:\n",
    "    n_notes = len(pitchInst) - len(pitchInst) % seq_length\n",
    "    train_notes = np.stack([pitchInst[key].head(n_notes) for key in key_order], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "train_notes[:,0] = train_notes[:,0] + 24\n",
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1729777314906,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "BTRgKfp-oBcf"
   },
   "outputs": [],
   "source": [
    "# from tensorFlow MusGen tutorial \n",
    "def create_sequences(\n",
    "    dataset: tf.data.Dataset,\n",
    "    seq_length: int,\n",
    "    vocab_size: int,\n",
    ") -> tf.data.Dataset:\n",
    "  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
    "  seq_length = seq_length+1\n",
    "\n",
    "  # Take 1 extra for the labels\n",
    "  windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "\n",
    "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "  sequences = windows.flat_map(flatten)\n",
    "\n",
    "  # Split the labels\n",
    "  def split_labels(sequences):\n",
    "    inputs = sequences[:-1]\n",
    "    labels_dense = sequences[-1]\n",
    "    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1729777317788,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "vvUPy1h-pgwL",
    "outputId": "772d3214-91f8-4e23-f674-9c0c29546add"
   },
   "outputs": [],
   "source": [
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
    "seq_ds.__len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1729777346217,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "FAdNRRuhxD2b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = n_notes  - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1729777351153,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "0MoxpDNIxJF1",
    "outputId": "4b5b7093-7e45-4672-b4b9-b351ca9ae3cb"
   },
   "outputs": [],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1729777377807,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "U6nNWGwJyDQE"
   },
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "  mse = (y_true - y_pred) ** 2\n",
    "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "  return tf.reduce_mean(mse + positive_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1729777385441,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "yaHEn45JyExj",
    "outputId": "9486ced4-b5cb-4403-a0d6-73293f0d06de"
   },
   "outputs": [],
   "source": [
    "# definition for the inputs.  Note how num of inputs is realted to size of key_order global\n",
    "input_shape = (seq_length, len(key_order))\n",
    "learning_rate = 0.010\n",
    "\n",
    "#input layer\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "#hidden layers\n",
    "x = tf.keras.layers.LSTM(64, return_sequences=True)(inputs)\n",
    "#x = tf.keras.layers.Dropout(0.50, seed=seed)(x) #dropout layer\n",
    "x = tf.keras.layers.LSTM(8, return_sequences=True)(x)\n",
    "#x = tf.keras.layers.Dropout(0.50, seed=seed)(x) #dropout layer\n",
    "x = tf.keras.layers.LSTM(8, return_sequences=False)(x) #last layer to outputs\n",
    "\n",
    "\n",
    "\n",
    "outputs = {\n",
    "  'interval': tf.keras.layers.Dense(49, activation='softmax', name='interval')(x),\n",
    "  'step': tf.keras.layers.Dense(1, name='step')(x),\n",
    "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = {\n",
    "      'interval':tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "      'step': mse_with_positive_pressure,\n",
    "      'duration': mse_with_positive_pressure,\n",
    "}\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1729777404726,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "nxD0f65oyGQ8"
   },
   "outputs": [],
   "source": [
    "# these are the three outputs of the model\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    loss_weights={\n",
    "        'interval': 1.0,\n",
    "        'step': 1.0,\n",
    "        'duration':1.0,\n",
    "    },\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "error",
     "timestamp": 1729777408966,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "0uYYRkKdyhTW",
    "outputId": "6612f8d7-48c3-49a1-8487-e2c0fa695763"
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1729702148836,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "zAww8xc7zAqc"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./training_checkpoints/ckpt_{epoch}.weights.h5',\n",
    "        save_weights_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=4,\n",
    "        verbose=1,\n",
    "        start_from_epoch=2,\n",
    "        restore_best_weights=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4492,
     "status": "ok",
     "timestamp": 1729702158732,
     "user": {
      "displayName": "Teo Vargo",
      "userId": "09124687834550019193"
     },
     "user_tz": -60
    },
    "id": "fxjUzIZUBFBW",
    "outputId": "ca635b70-07f4-4bec-e6ee-afc9a1e81462"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 8\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIMee7mLBQ5z"
   },
   "outputs": [],
   "source": [
    "def predict_next_note(\n",
    "    notes: np.ndarray,\n",
    "    init_pitch: float,\n",
    "    model: tf.keras.Model,\n",
    "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
    "  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  interval_logits = predictions['interval']\n",
    "  step = predictions['step']\n",
    "  duration = predictions['duration']\n",
    "\n",
    "  interval_logits /= temperature \n",
    "  interval = tf.random.categorical(interval_logits, num_samples=1) \n",
    "  interval = tf.squeeze(interval, axis=-1) \n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "  interval = interval - 24\n",
    "  pitch = init_pitch + interval\n",
    "\n",
    "  # `step` and `duration` values should be non-negative\n",
    "\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "  pitch = tf.minimum(120, pitch)\n",
    "  pitch = tf.maximum(30, pitch)\n",
    "\n",
    "  return int(pitch), int(interval), float(step), float(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1.0\n",
    "num_predictions = 40\n",
    "song = skip_list[0]\n",
    "\n",
    "for song in skip_list:\n",
    "  test_notes = pitchInst[pitchInst['melid'] == song].reset_index()\n",
    "  sample_notes = np.stack([test_notes[key] for key in key_order], axis=1)\n",
    "\n",
    "  input_notes = sample_notes[:seq_length]\n",
    "\n",
    "  #\n",
    "  tempo = test_notes['tempo'].iloc[seq_length]\n",
    "  inst = test_notes['instrument_num'].iloc[seq_length]\n",
    "  key = test_notes['key_num'].iloc[seq_length]\n",
    "  title = test_notes['title'].iloc[seq_length]\n",
    "  performer = test_notes['performer'].iloc[seq_length]\n",
    "  instrument_name = test_notes['instrument'].iloc[seq_length]\n",
    "  pitch = test_notes['pitch'].iloc[seq_length]\n",
    "\n",
    "\n",
    "  generated_notes = []\n",
    "  prev_start = 0\n",
    "  for i in range(num_predictions): #THERE ARE PROBLEMS HERE\n",
    "    pitch, interval ,step, duration = predict_next_note(input_notes, pitch ,model, temperature)\n",
    "    # interval = interval - 24\n",
    "    #pitch = pitch + interval\n",
    "    start = prev_start\n",
    "    end = start + duration\n",
    "    # TODO:\n",
    "    # This line has to change when you change the inputs to the model.  The input_note\n",
    "    # that is getting appended to input notes needs to have the correct number of \n",
    "    # fields cause it is gonna get fed back into the model.predict function\n",
    "    input_note = (interval, step, duration, tempo, inst, key)\n",
    "    # input_note = (pitch, step, duration, tempo, inst, key)\n",
    "    generated_notes.append((*input_note, pitch ,start, end))\n",
    "    input_notes = np.delete(input_notes, 0, axis=0)\n",
    "    input_notes = np.append(input_notes , np.expand_dims(input_note, 0), axis=0) \n",
    "    prev_start = start + step\n",
    "    \n",
    "\n",
    "  generated_notes = pd.DataFrame(\n",
    "      generated_notes, columns=(*key_order, 'pitch' ,'start', 'end'))\n",
    "\n",
    "test_notes = test_notes[:seq_length]\n",
    "start_df = test_notes.drop(['interval'], axis=1)\n",
    "\n",
    "# string together the first training data and the generated notes\n",
    "full_sequence = pd.concat([start_df, generated_notes], ignore_index=True)\n",
    "\n",
    "example_file = f\"Song-{song}_seq-{seq_length}-{performer}-{title}.midi\"  # adds a prefix to the sample filename\n",
    "example_pm = my_functions.notes_to_midi(full_sequence[['pitch', 'step', 'duration', 'tempo']], out_file=example_file, instrument_name='Acoustic Grand Piano')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_piano_roll(full_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_piano_roll(generated_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_distributions(generated_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_functions.plot_distributions(test_notes)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbAUZAKMT3LWx3S3x1qvHL",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
